{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jw/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from train import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_size = 150\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = LabelledImageDataset('dataset/train', transform = A.Compose([\n",
    "        A.Resize(image_size, image_size),   \n",
    "        A.Normalize()\n",
    "    ]))\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "\n",
    "val_data = LabelledImageDataset('dataset/val', transform = A.Compose([\n",
    "        A.Resize(image_size, image_size),   \n",
    "        A.Normalize()\n",
    "    ]))\n",
    "val_loader = DataLoader(val_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "def display_img(img,label):\n",
    "    print(f\"Label: {'primary' if label else 'footway'}\")\n",
    "    plt.imshow(img.permute(1,2,0))\n",
    "\n",
    "train_features, train_labels = next(iter(val_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l in zip(train_features, train_labels):\n",
    "    #plt.imshow(i.numpy().transpose(1,2,0))\n",
    "    plt.title(l)\n",
    "    img = i.squeeze()\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    print(f\"Label: {'primary' if l else 'footway'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_batch(dl):\n",
    "    \"\"\"Plot images grid of single batch\"\"\"\n",
    "    for images, labels in dl:\n",
    "        fig,ax = plt.subplots(figsize = (16,12))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images,nrow=16).permute(1,2,0))\n",
    "        break\n",
    "        \n",
    "show_batch(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HighwayClassifier().to(device)\n",
    "\n",
    "num_epochs = 30\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr)\n",
    "loss_fn = F.binary_cross_entropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.679\n",
      "[2] loss: 0.498\n",
      "[3] loss: 0.449\n",
      "[4] loss: 0.376\n",
      "[5] loss: 0.512\n",
      "[6] loss: 0.371\n",
      "[7] loss: 0.365\n",
      "[8] loss: 0.236\n",
      "[9] loss: 0.218\n",
      "[10] loss: 0.178\n",
      "[11] loss: 0.140\n",
      "[12] loss: 0.113\n",
      "[13] loss: 0.110\n",
      "[14] loss: 0.044\n",
      "[15] loss: 0.011\n",
      "[16] loss: 0.001\n",
      "[17] loss: 0.008\n",
      "[18] loss: 0.210\n",
      "[19] loss: 0.059\n",
      "[20] loss: 0.092\n",
      "[21] loss: 0.004\n",
      "[22] loss: 0.000\n",
      "[23] loss: 0.000\n",
      "[24] loss: 0.000\n",
      "[25] loss: 0.000\n",
      "[26] loss: 0.000\n",
      "[27] loss: 0.000\n",
      "[28] loss: 0.000\n",
      "[29] loss: 0.000\n",
      "[30] loss: 0.000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#fitting the model on training data and record the result after each epoch\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    # print every epoch\n",
    "    print(f'[{epoch + 1}] loss: {running_loss / num_batches:.3f}')\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights/model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor([0.9200])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "val_data = LabelledImageDataset('dataset/val', transform = A.Compose([\n",
    "        A.Resize(image_size, image_size),   \n",
    "        A.Normalize()\n",
    "    ]))\n",
    "val_loader = DataLoader(val_data, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "# visualize\n",
    "def display_eval(img,pred,actual):\n",
    "    print(f\"Predicted: {'primary' if pred else 'footway'}\")\n",
    "    print(f\"Actual: {'primary' if actual else 'footway'}\")\n",
    "    plt.imshow(img.permute(1,2,0))\n",
    "\n",
    "num_correct = 0\n",
    "num_total = 0\n",
    "for val_features, val_labels in val_loader:\n",
    "    # print(f\"Feature batch shape: {val_features.size()}\")\n",
    "    # print(f\"Labels batch shape: {val_labels.size()}\")\n",
    "\n",
    "    for i, actual in zip(val_features, val_labels):\n",
    "        img = i.squeeze()\n",
    "        pred = model(img.unsqueeze(0).to(device)).item() > 0.5\n",
    "        num_correct += (pred == actual)\n",
    "        num_total += 1\n",
    "        # plt.title(l)\n",
    "        # display_eval(img, pred, actual)\n",
    "        # plt.show()\n",
    "\n",
    "print(f\"Accuracy: {num_correct / num_total}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2efa3268f2e9dba20e3842f3e8c76f5b8ccb385e1128f4498e0932bb9350cc48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
